{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform strategic environmental assessment \n",
    "Purpose: get average housing density, area of rangeslands impacted, area of each land cover type impacted for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona as fi\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import ogr\n",
    "import json\n",
    "import geojson\n",
    "import os\n",
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate zonal stats\n",
    "The outputs are the sum or mean of the input raster (environmental metric) for each \"zone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcZS(zones, dissField_all, dissField_region, rasterPath, statsList, categorical, calcAllRegions, areaField):\n",
    "    ## rasterstats manual: https://pythonhosted.org/rasterstats/manual.html#zonal-statistics\n",
    "    ### calculate zonal stats for each region\n",
    "    ## dissolve\n",
    "    zones_diss_region = zones.dissolve(by=dissField_region)\n",
    "    ## calc zonal stats\n",
    "    stats_region = zonal_stats(zones_diss_region, rasterPath, categorical = categorical, stats=statsList)\n",
    "    ## add region as new key/value to list of dictionaries (stats_region output format)\n",
    "    for counter, region in enumerate(zones_diss_region.index):\n",
    "        stats_region[counter][\"region\"] = region\n",
    "    ## convert to pd df\n",
    "    stats_region_df = pd.DataFrame(stats_region)\n",
    "    \n",
    "    if calcAllRegions == True:\n",
    "        ### calculate zonal stats across all regions\n",
    "        ## add field for dissolving\n",
    "        zones[dissField_all] = 1\n",
    "        ## dissolve\n",
    "        zones_diss_all = zones.dissolve(by=dissField_all)\n",
    "        ## calc zonal stats\n",
    "        stats_all = zonal_stats(zones_diss_all, rasterPath, categorical = categorical, stats=statsList)\n",
    "        ## convert to pd df\n",
    "        stats_all_df = pd.DataFrame(stats_all)\n",
    "        ## Add \"region\" column, set value to \"All\"\n",
    "        stats_all_df[\"region\"] = \"all\"\n",
    "        \n",
    "        ## concat the two pd dfs\n",
    "        stats_concat = pd.concat([stats_all_df,stats_region_df], axis = 0, sort=True) \n",
    "        \n",
    "    else:\n",
    "        stats_concat = stats_region_df\n",
    "    \n",
    "        ## Create table of area sums of all selected sites\n",
    "        sumSelectedSitesByZone = zones.groupby([dissField_region])[areaField].sum().reset_index()\n",
    "\n",
    "        ## change area column\n",
    "        sumSelectedSitesByZone = sumSelectedSitesByZone.rename(columns = {\"Area\": \"area_allSelSites_km2\", dissField_region: \"region\"})[[\"region\",\"area_allSelSites_km2\"]]\n",
    "\n",
    "        ## merge the two df\n",
    "        stats_concat = stats_concat.merge(sumSelectedSitesByZone, how = \"inner\", left_on=\"region\", right_on=\"region\")\n",
    "\n",
    "        ## calculate percentage\n",
    "        #stats_concat[\"percent_selSites\"] = stats_concat[\"Area\"]/stats_concat['area_allSelSites_km2']\n",
    "    \n",
    "    return stats_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets\n",
    "### Selected Project Areas (SPAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infrastructureType = \"tx_longHaul\" ## selSites, tx, or tx_longHaul\n",
    "mainDir = \"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\\"\n",
    "\n",
    "if infrastructureType == \"selSites\":\n",
    "    ## selected sites folder\n",
    "    allFCfolder = \"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\spatialDisaggregation\\\\selectedsites_cleaned_shp\"\n",
    "    allFCList = [file for file in os.listdir(allFCfolder) if file.endswith(\".shp\")]\n",
    "    suffix = \".shp\"\n",
    "    suffix_solar = \".shp\"\n",
    "    regionField_RESOLVEZONE = \"RESOLVE_ZO\"\n",
    "    \n",
    "if infrastructureType == \"tx\":\n",
    "    ## selected sites folder\n",
    "    spDisaggFolder = os.path.join(mainDir,\"spatialDisaggregation\\\\\") #^^\n",
    "    allFCfolder = os.path.join(spDisaggFolder, \"LeastCostPath\\\\SD_LCP_122018\\\\SD_LCP_diss\")    \n",
    "    allFCList = [file for file in os.listdir(allFCfolder) if file.endswith(\".shp\")]\n",
    "    suffix = \"_copy_LCP_erasedBuffLine_diss.shp\"\n",
    "    suffix_solar = \"_LCP_erasedBuffLine_diss.shp\"\n",
    "    regionField_RESOLVEZONE = \"RESOLVE_ZO\"\n",
    "    \n",
    "if infrastructureType == \"tx_longHaul\":\n",
    "    ## selected sites folder\n",
    "    #spDisaggFolder = os.path.join(mainDir,\"spatialDisaggregation\\\\\") #^^\n",
    "    allFCfolder = os.path.join(mainDir, \"dataCollection\\\\existingEnergyInfrastructure\\\\BLMRecentlyApprovedProjects\")    \n",
    "    allFCList = [file for file in os.listdir(allFCfolder) if file.endswith(\".shp\")]\n",
    "    suffix = \"_copy_LCP_erasedBuffLine_diss.shp\"\n",
    "    suffix_solar = \"_LCP_erasedBuffLine_diss.shp\"\n",
    "    regionField_RESOLVEZONE = \"RESOLVE_ZO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental metric raster datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## housing density layer:\n",
    "hd_path = r'C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\dataCollection\\envImpactAssessment\\housingDensity\\housingDen2010_merged_raster_proj.tif'\n",
    "## agricultural land\n",
    "agLand_path = r'C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\dataCollection\\envImpactAssessment\\gapLC\\gaplc_merged_proj_agLand.tif'\n",
    "## all land cover types\n",
    "agLand_allCat_path = r'C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\dataCollection\\envImpactAssessment\\gapLC\\gaplc_merged_proj.tif'\n",
    "## agricultural alnds, but reclassed\n",
    "agLand_reclass_path = r'C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\dataCollection\\envImpactAssessment\\gapLC\\gaplc_merged_proj_reclassAg.tif'\n",
    "## rangelands \n",
    "rangelands_path = r'C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\dataCollection\\envImpactAssessment\\RangeGrd\\nrirng_RANGE_NUM_proj.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop zonal stats through SPAs for each raster dataset\n",
    "Change the environmental metric raster and run the below cells for each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envMetric = \"housingDensity\" ## housingDensity, landCover, rangelands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of scenarios and technologies to loop over for each env metric raster dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List scenarios\n",
    "scenList = [\"In-State x Capped Basecase\",  \"Full WECC x Capped Basecase\", \"Part WECC x Capped Basecase\", \\\n",
    "                        \"In-State x Capped highDER\", \"Full WECC x Capped highDER\", \"Part WECC x Capped highDER\", \\\n",
    "                        \"In-State x Capped lowBatt\", \"Full WECC x Capped lowBatt\", \"Part WECC x Capped lowBatt\",\\\n",
    "                        \"In-State BaseUsex Basecase\", \"Full WECC BaseUsex Basecase\", \"Part WECC BaseUsex Basecase\", \\\n",
    "                         \"In-State BaseUsex highDER\", \"Full WECC BaseUsex highDER\", \"Part WECC BaseUsex highDER\", \\\n",
    "                         \"In-State BaseUsex lowBatt\",  \"Full WECC BaseUsex lowBatt\", \"Part WECC BaseUsex lowBatt\",\\\n",
    "                        \"In-State xW2W No Cap Basecase\",\\\n",
    "                        \"Full WECC xW2W No Cap Basecase\",\\\n",
    "                        \"Part WECC xW2W No Cap Basecase\",\\\n",
    "                         \"In-State xW2W No Cap highDER\", \"Full WECC xW2W No Cap highDER\", \\\n",
    "                         \"In-State xW2W No Cap lowBatt\", \"Full WECC xW2W No Cap lowBatt\"]\n",
    "\n",
    "## technologies\n",
    "techList = [\"Geothermal\", \"Wind\", \"Solar\"]\n",
    "\n",
    "df_RESOLVEscenarios_total = pd.read_csv(os.path.join(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\\", \"RESOLVEoutputs\", \"Results Summary Workbook_v11_20181214_total.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions for Housing density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if envMetric == \"housingDensity\":\n",
    "    \n",
    "    ## raster file path\n",
    "    rasterPath = hd_path\n",
    "\n",
    "    ## stats to calculate\n",
    "    statList = ['count', 'mean', 'min', 'max', 'median']\n",
    "\n",
    "    ## whether or not the raster is categorical\n",
    "    categoricalRaster = False\n",
    "\n",
    "    ## whether to calculate the \"all\" in the \"region\" column\n",
    "    calcAllRegions = True\n",
    "\n",
    "    ## column order of final csv\n",
    "    master_df_col_list = [\"tech\", \"envCat\", \"scenario\", \"selSites\", \"region\", 'selSitesExist', 'count', 'mean', 'min', 'max', 'median']\n",
    "\n",
    "    ## empty dataframe of results\n",
    "    master_df = pd.DataFrame(columns = master_df_col_list)\n",
    "\n",
    "    resultsFileName = os.path.join(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\\",  \"areaImpacted_\" + infrastructureType + \"_SG12_housingDensity_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions for land cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if envMetric == \"landCover\":\n",
    "    ## raster file path\n",
    "    rasterPath = agLand_reclass_path #agLand_allCat_path\n",
    "\n",
    "    ## stats to calculate\n",
    "    statList = []\n",
    "\n",
    "    ## whether or not the raster is categorical\n",
    "    categoricalRaster = True\n",
    "\n",
    "    ## whether to calculate the \"all\" in the \"region\" column\n",
    "    ## don't need to calculate for all regions because this can be done on the df later (by adding across all zones)\n",
    "    calcAllRegions = False\n",
    "\n",
    "    ## column order of final csv\n",
    "    master_df_col_list = [\"tech\", \"envCat\", \"scenario\", \"selSites\", \"region\", 'selSitesExist', \"area_allSelSites_km2\", 0, 553, 555, 556, 557]\n",
    "\n",
    "    ## empty dataframe of results\n",
    "    master_df = pd.DataFrame(columns = master_df_col_list)\n",
    "\n",
    "    resultsFileName = os.path.join(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\\",  \"areaImpacted_\" + infrastructureType + \"_SG13_gaplc_SG13_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions for rangelands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if envMetric == \"rangelands\":\n",
    "\n",
    "    ## raster file path\n",
    "    rasterPath = rangelands_path #agLand_allCat_path\n",
    "\n",
    "    ## stats to calculate\n",
    "    statList = []\n",
    "\n",
    "    ## whether or not the raster is categorical\n",
    "    categoricalRaster = True\n",
    "\n",
    "    ## whether to calculate the \"all\" in the \"region\" column\n",
    "    ## don't need to calculate for all regions because this can be done on the df later (by adding across all zones)\n",
    "    calcAllRegions = False\n",
    "\n",
    "    ## column order of final csv\n",
    "    master_df_col_list = [\"tech\", \"envCat\", \"scenario\", \"selSites\", \"region\", 'selSitesExist', \"area_allSelSites_km2\", 0, 1,2,3,4,5,11,12,21,22,23,24,31,80,81,82]\n",
    "\n",
    "    ## empty dataframe of results\n",
    "    master_df = pd.DataFrame(columns = master_df_col_list)\n",
    "\n",
    "    resultsFileName = os.path.join(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\\", \"areaImpacted_\" + infrastructureType + \" _SG17_rangelands_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1551758663.4143205\n",
      "Working on long haul lines\n",
      "Working on BLM_transmission_line_pref_route_energy_b2h_76mBuff_state.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grace\\Anaconda3\\lib\\site-packages\\rasterstats\\io.py:294: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed BLM_transmission_line_pref_route_energy_b2h_76mBuff_state.shp\n",
      "0.02578161160151164 minutes\n",
      "Working on BLM_transmission_line_pref_route_energy_gateway_south_v2_76mBuff_state.shp\n",
      "Completed BLM_transmission_line_pref_route_energy_gateway_south_v2_76mBuff_state.shp\n",
      "0.04541409413019816 minutes\n",
      "Working on BLM_transmission_line_pref_route_energy_gateway_west_v2_76mBuff_state.shp\n",
      "Completed BLM_transmission_line_pref_route_energy_gateway_west_v2_76mBuff_state.shp\n",
      "0.056219605604807536 minutes\n",
      "Working on BLM_transmission_line_pref_route_energy_southline_state.shp\n",
      "Completed BLM_transmission_line_pref_route_energy_southline_state.shp\n",
      "0.07480728228886922 minutes\n",
      "Working on BLM_transmission_line_pref_route_energy_sunzia_123mBuff_state.shp\n",
      "Completed BLM_transmission_line_pref_route_energy_sunzia_123mBuff_state.shp\n",
      "0.11414523919423421 minutes\n",
      "Working on BLM_transmission_line_pref_route_energy_transwest_express_centerline_76mBuff_state.shp\n",
      "Completed BLM_transmission_line_pref_route_energy_transwest_express_centerline_76mBuff_state.shp\n",
      "0.18231168190638225 minutes\n",
      "^^^^ Total time for completion: 0.1823947787284851 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(start_time)\n",
    "\n",
    "if infrastructureType == \"tx_longHaul\":\n",
    "    print(\"Working on long haul lines\")\n",
    "    for line in allFCList:\n",
    "        ## read selected sites (shp) as geodataframe\n",
    "        sp = gpd.read_file(os.path.join(allFCfolder, line))\n",
    "        print(\"Working on \" + line)\n",
    "\n",
    "        if len(sp) > 0:\n",
    "\n",
    "            ## apply Zonal stats for housing density\n",
    "            zs_out = calcZS(zones = sp, dissField_all = \"dissolve\", dissField_region = \"STATE\", rasterPath = rasterPath, \\\n",
    "                            statsList = statList, categorical = categoricalRaster, calcAllRegions = calcAllRegions, areaField = \"Area\")\n",
    "\n",
    "            ## apply Zonal stats for agland\n",
    "            #agLand_all = calcZS(zones = sp, dissField_all = \"gridcode\", dissField_region = geography['regionField'], rasterPath = agLand_path, statsList = ['count', 'sum'])\n",
    "\n",
    "            ## add technology\n",
    "            zs_out[\"tech\"] = \"none\"\n",
    "\n",
    "            ## add scenario name\n",
    "            zs_out[\"scenario\"] = \"none\"\n",
    "\n",
    "            ## add env cat\n",
    "            zs_out[\"envCat\"] = \"none\"\n",
    "\n",
    "            ## add selected sites file name\n",
    "            zs_out[\"selSites\"] = line\n",
    "\n",
    "            ## add flag for whether or not there were selected sites for this geography\n",
    "            zs_out[\"selSitesExist\"] = 1\n",
    "\n",
    "            ## append area_df to master df\n",
    "            master_df = pd.concat([master_df, zs_out], axis = 0, sort = True)\n",
    "\n",
    "            ## reorder fields:\n",
    "            master_df = master_df[master_df_col_list]\n",
    "\n",
    "            print(\"Completed \" + line)\n",
    "            print(str((time.time() - start_time)/(60)) + \" minutes\")\n",
    "    \n",
    "else:\n",
    "    for tech in techList:\n",
    "        ## categories\n",
    "        if tech == \"Geothermal\":\n",
    "            catList = {\"Cat1\" : \"geothermal_cat1b\", \"Cat2\" : \"geothermal_cat2f\",\\\n",
    "                    \"Cat3\" : \"geothermal_cat3\", \"Cat4\": \"geothermal_cat4\"}\n",
    "            suffixFinal = suffix\n",
    "\n",
    "        if tech == \"Wind\":\n",
    "            catList = {\"Cat1\" : \"wind_0_03_nonEnv_r3_cat1b_singlepart_gt1km2\",\"Cat2\" : \"wind_0_03_nonEnv_r3_cat2f_singlepart_gt1km2\",\\\n",
    "                    \"Cat3\" : \"wind_0_03_nonEnv_r3_cat3c_singlepart_gt1km2\", \"Cat4\": \"wind_0_03_nonEnv_r3_cat4_singlepart_gt1km2\"}\n",
    "            suffixFinal = suffix\n",
    "\n",
    "        if tech == \"Solar\":\n",
    "            catList = {\"Cat1\" : \"solarPV_0_0_nonEnv_r1_cat1b_singlepart_gt1km2\",\"Cat2\" : \"solarPV_0_0_nonEnv_r1_cat2f_singlepart_gt1km2\",\\\n",
    "                    \"Cat3\" : \"solarPV_0_0_nonEnv_r1_cat3c_singlepart_gt1km2\", \"Cat4\": \"solarPV_0_0_nonEnv_r1_cat4_singlepart_gt1km2\"}\n",
    "            suffixFinal = suffix_solar\n",
    "        print(\"===================================\")\n",
    "        print(tech)\n",
    "\n",
    "        for cat in catList:\n",
    "            for scen in scenList:\n",
    "                scen = scen.replace(\"x\", cat)\n",
    "                if scen in df_RESOLVEscenarios_total.columns: \n",
    "                    scenName_field = scen.replace(\" \", \"_\").replace(\"-\", \"\")                \n",
    "                    print(\"\")\n",
    "                    geographyList = []\n",
    "                    separator = \"_\" \n",
    "                    oos_RESOLVE_filename = separator.join([catList[cat], \"PA\", \"OOS_RESOLVEZONE\", \"net\", scenName_field, \"selected\"]) + suffixFinal\n",
    "                    oos_STATE_filename = separator.join([catList[cat], \"PA\", \"state\", \"net\", scenName_field, \"selected\"]) + suffixFinal\n",
    "                    instate_filename = separator.join([catList[cat], \"PA\", \"CA_RESOLVEZONE\", \"net\", scenName_field, \"selected\"]) + suffixFinal\n",
    "\n",
    "                    if \"W2W\" in scenName_field and \"InState\" not in scenName_field:\n",
    "                        ## append both state and in-state filenames to geoList\n",
    "                        geographyList.append({\"file\": oos_STATE_filename, \"regionField\": \"STATE\"})\n",
    "                        geographyList.append({\"file\": instate_filename, \"regionField\": regionField_RESOLVEZONE})\n",
    "                        print(\"W2W scenario for \" + oos_STATE_filename + \" and \" + instate_filename)\n",
    "\n",
    "                    if \"InState\" in scenName_field:\n",
    "                        ## append only state filename to geoList\n",
    "                        geographyList.append({\"file\": instate_filename, \"regionField\": regionField_RESOLVEZONE})\n",
    "                        print(\"InState scenario for \" + instate_filename)\n",
    "\n",
    "                    if any(txt in scenName_field for txt in [\"Capped\",\"BaseUseCat1\"]) and \"InState\" not in scenName_field:\n",
    "                        ## append both OOS RESOLVE ZONES and in-state filenames to geoList\n",
    "                        geographyList.append({\"file\": oos_RESOLVE_filename, \"regionField\": regionField_RESOLVEZONE})\n",
    "                        geographyList.append({\"file\": instate_filename, \"regionField\": regionField_RESOLVEZONE})\n",
    "                        print(\"OOS RESOLVE scenario for \" + oos_RESOLVE_filename + \" and \" + instate_filename)\n",
    "\n",
    "                    ## loop through each element of geoList\n",
    "                    for geography in geographyList:\n",
    "                        ## if file is in the geodatabase and it has not already been analyzed\n",
    "                        ## ex: \"geothermal_cat1b_PA_CA_RESOLVEZONE_net_Part_WECC_Cat1_Capped_highDER_selectedcriticalHabitat_SG05\" not in list of these in the master_df\n",
    "                        if geography['file'] in allFCList: #and geography['file']+envData[\"envDataLabel\"] not in (master_df[\"selSites\"]+master_df['envData']).tolist():\n",
    "\n",
    "                            ## read selected sites (shp) as geodataframe\n",
    "                            sp = gpd.read_file(os.path.join(allFCfolder, geography['file']))\n",
    "\n",
    "                            if len(sp) > 0:\n",
    "\n",
    "                                ## apply Zonal stats for housing density\n",
    "                                zs_out = calcZS(zones = sp, dissField_all = \"dissolve\", dissField_region = geography['regionField'], rasterPath = rasterPath, \\\n",
    "                                                statsList = statList, categorical = categoricalRaster, calcAllRegions = calcAllRegions, areaField = \"Area\")\n",
    "\n",
    "                                ## apply Zonal stats for agland\n",
    "                                #agLand_all = calcZS(zones = sp, dissField_all = \"gridcode\", dissField_region = geography['regionField'], rasterPath = agLand_path, statsList = ['count', 'sum'])\n",
    "\n",
    "                                ## add technology\n",
    "                                zs_out[\"tech\"] = tech\n",
    "\n",
    "                                ## add scenario name\n",
    "                                zs_out[\"scenario\"] = scenName_field\n",
    "\n",
    "                                ## add env cat\n",
    "                                zs_out[\"envCat\"] = cat\n",
    "\n",
    "                                ## add selected sites file name\n",
    "                                zs_out[\"selSites\"] = geography['file']\n",
    "\n",
    "                                ## add flag for whether or not there were selected sites for this geography\n",
    "                                zs_out[\"selSitesExist\"] = 1\n",
    "\n",
    "                                ## append area_df to master df\n",
    "                                master_df = pd.concat([master_df, zs_out], axis = 0, sort = True)\n",
    "\n",
    "                                ## reorder fields:\n",
    "                                master_df = master_df[master_df_col_list]\n",
    "\n",
    "                                print(\"Completed \" + geography[\"file\"])\n",
    "                                print(str((time.time() - start_time)/(60)) + \" minutes\")\n",
    "\n",
    "                            else:\n",
    "                                ## Create single row dataframe with NA for region and area_km2 to indicate that there are no selected sites for that scenario/geography\n",
    "                                zs_out = pd.DataFrame(data = {\"tech\": [tech], \"envCat\": [cat], \"scenario\": [scenName_field], \\\n",
    "                                                               \"selSites\": [geography['file']], \"region\": [\"NA\"], \"selSitesExist\": [0]})\n",
    "\n",
    "                                ## append area_df to master df\n",
    "                                master_df = pd.concat([master_df, zs_out], axis = 0)\n",
    "\n",
    "                                ## reorder fields:\n",
    "                                master_df = master_df[master_df_col_list]\n",
    "\n",
    "                                print(\"***There are no selected sites for empty \" + geography[\"file\"])\n",
    "                        else:\n",
    "                            print(\"Not in gdb or already analyzed and in master_df: \" + geography['file'])\n",
    "\n",
    "                    print(str((time.time() - start_time)/(60)) + \" minutes\")\n",
    "\n",
    "## reorder fields:\n",
    "master_df = master_df[master_df_col_list]\n",
    "master_df.to_csv(path_or_buf = resultsFileName, index = False)\n",
    "                            \n",
    "elapsed_time = (time.time() - start_time)/(60)\n",
    "print(\"^^^^ Total time for completion: \" + str(elapsed_time) + \" minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
