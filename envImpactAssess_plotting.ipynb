{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Master DF for plottin \n",
    "Purpose: takes all Strategic environmental assessment output csvs and merges them into one large table in the long format for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "#plotly.tools.set_credentials_file(username='grace.cc.wu', api_key='mfClrA9eHWhuOwBJLR3h')\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "matplotlib.style.use('ggplot')\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess input CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: pre-process envData csv (to use inside a loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCSV(csv, gaplc_df):\n",
    "    selSite_df = pd.read_csv(csv, keep_default_na=False)\n",
    "\n",
    "    ''' ### ADD FLAG COLUMN, impactEval ### '''\n",
    "    ## add new column for impactEval (1 = an impact assessment was performed for the env categories)\n",
    "    selSite_df[\"impactEval\"] = 1\n",
    "    ## Where the area_envData_km2 column was not calculated (empty feature classes), then set value to 0 (applies to jupyter notebook anayses)\n",
    "    selSite_df.loc[selSite_df.area_envData_km2.astype(str) == \"NA\", 'impactEval'] = 0\n",
    "\n",
    "    ''' ### SUBSET GAPLC TO TECHNOLOGIES IN THE CSV ### '''\n",
    "    techList = selSite_df[\"tech\"].unique()\n",
    "    gaplc_df_sub = gaplc_df[(gaplc_df[\"tech\"].isin(techList))]\n",
    "\n",
    "    ''' ### MERGE CSV WITH GAPLC ### '''\n",
    "    ## merge selSite_df with the gaplc df to get all the \"area_allSelSites_km2\" and \"selSiteExist\"\n",
    "    selSite_merged_df = selSite_df.merge(gaplc_df_sub[[\"selSites\", \"region\", \"selSitesExist\", \"area_allSelSites_km2\", \"envCat\", \"tech\"]], how = \"outer\", on =  [\"selSites\", \"region\"])\n",
    "\n",
    "    ''' ### ADD INFRASTRUCTURE COLUMN ### '''\n",
    "    if \"selSite\" in csv:\n",
    "        selSite_merged_df[\"infrastructure\"] = \"generation\"\n",
    "    if \"tx\" in csv:\n",
    "        selSite_merged_df[\"infrastructure\"] = \"transmission\"\n",
    "\n",
    "    ''' ### EXPAND envData COLUMN TO JOINED GAPLC ROWS ### '''\n",
    "    selSite_merged_df[\"envData\"] = selSite_df.envData.unique()[0]\n",
    "\n",
    "    ''' ### CONVERT area_allSelSites_km2_y TO ZERO FROM \"\" ### '''\n",
    "    ## if sites do not exist (selSitesExist = 0), then make sure area_allSelSites_km2_y = 0 (no selected sites, or empty feature class/shapefile)\n",
    "    selSite_merged_df.loc[selSite_merged_df.selSitesExist == 0, \"area_allSelSites_km2_y\"] = 0\n",
    "\n",
    "    ''' ### CONVERT area_envData_km2 TO ZERO FROM NaN OR BLANK ### '''\n",
    "    print(selSite_merged_df.area_envData_km2.dtype)\n",
    "    ## if a column value for \"area_envData_km2\" is NaN, assign 0 \n",
    "    selSite_merged_df.loc[(selSite_merged_df['area_envData_km2'].isna()), 'area_envData_km2'] = 0\n",
    "    ## if a column value for \"area_envData_km2\" is == \"NA\", assign 0 (these are runs with empty feature classes or no selected sites) \n",
    "    selSite_merged_df.loc[(selSite_merged_df['area_envData_km2'].astype(str) ==\"NA\"), 'area_envData_km2'] = 0\n",
    "    ## if a column value for \"area_envData_km2\" is blank/empty, assign to value of area_allSelSites_km2_y  \n",
    "    ## (for \"erased\" csvs, if the column is empty, that means there was complete overlap between the sites and the env dataset, so assign area_envData_km2 to area_selSite_km2)\n",
    "    selSite_merged_df.loc[(selSite_merged_df['area_envData_km2'].astype(str) ==\"\"), 'area_envData_km2'] = selSite_merged_df.area_allSelSites_km2_y\n",
    "    ## convert column datatype to float \n",
    "    selSite_merged_df.area_envData_km2 = pd.to_numeric(selSite_merged_df.area_envData_km2)\n",
    "    print(selSite_merged_df.area_envData_km2.dtype)\n",
    "\n",
    "    '''### CREATE NEW COLUMNS: tech, envCat, area_allSelSites_km2 AFTER JOIN ###'''\n",
    "    selSite_merged_df[\"area_allSelSites_km2\"] = pd.to_numeric(selSite_merged_df[\"area_allSelSites_km2_y\"])\n",
    "    selSite_merged_df[\"tech\"] = selSite_merged_df[\"tech_y\"] \n",
    "    selSite_merged_df[\"envCat\"] = selSite_merged_df[\"envCat_y\"]\n",
    "\n",
    "    '''### CREATE NEW envCat_scen TO PARSE OUT BaseUSeCat1 AS \"Base\" ###'''\n",
    "    selSite_merged_df['envCat_scen'] = np.where(selSite_merged_df.selSites.str.contains(\"BaseUseCat1\"), \"Base\", selSite_merged_df.envCat) \n",
    "\n",
    "    '''### CREATE OR UPDATE FLAG COLUMNS FOR DIFFERENT \"ZEROS\": impactEval, scenRun ###'''\n",
    "    ## impactEval: assign value of 0 for all rows that had to be added after the merge\n",
    "    selSite_merged_df.loc[selSite_merged_df['impactEval'].isna(), 'impactEval'] = 0\n",
    "    selSite_merged_df.impactEval = selSite_merged_df.impactEval.astype(int) \n",
    "\n",
    "    ## scenRun: will add the = 0 flag later when the additional rows are added for scenarios that were not run\n",
    "    selSite_merged_df[\"scenRun\"] = 1\n",
    "\n",
    "    ''' ### PARSE OUT CATEGORICAL COLUMNS FROM selSites COLUMN ### '''\n",
    "    #### geography: InState, Full_WECC, Part_WECc\n",
    "    selSite_merged_df['geography'] = np.where(selSite_merged_df.selSites.str.contains(\"InState\"), \"InState\", \\\n",
    "                                              np.where(selSite_merged_df.selSites.str.contains(\"Full_WECC\"), \"Full_WECC\", \\\n",
    "                                                       np.where(selSite_merged_df.selSites.str.contains(\"Part_WECC\"), \"Part_WECC\",\"NA\")))\n",
    "\n",
    "    ## RESOLVE scenario (Capped_Basecase, Capped_highDER, etc.)\n",
    "    selSite_merged_df['RESOLVE_scenario'] = np.where(selSite_merged_df.selSites.str.contains(\"Capped_Basecase\"), \"Capped_Basecase\",\n",
    "                                  np.where(selSite_merged_df.selSites.str.contains(\"BaseUseCat1_Basecase\"), \"Capped_Basecase\",\n",
    "                                           np.where(selSite_merged_df.selSites.str.contains(\"BaseUseCat1_highDER\"), \"Capped_highDER\",\n",
    "                                                    np.where(selSite_merged_df.selSites.str.contains(\"BaseUseCat1_lowBatt\"), \"Capped_lowBatt\",\n",
    "                                                         np.where(selSite_merged_df.selSites.str.contains(\"Capped_highDER\"), \"Capped_highDER\",\n",
    "                                                                 np.where(selSite_merged_df.selSites.str.contains(\"Capped_lowBatt\"), \"Capped_lowBatt\",\n",
    "                                                                         np.where(selSite_merged_df.selSites.str.contains(\"No_Cap_Basecase\"), \"No_Cap_Basecase\",\n",
    "                                                                                 np.where(selSite_merged_df.selSites.str.contains(\"No_Cap_highDER\"), \"No_Cap_highDER\",\n",
    "                                                                                         np.where(selSite_merged_df.selSites.str.contains(\"No_Cap_lowBatt\"), \"No_Cap_lowBatt\", \"NA\")))))))))\n",
    "\n",
    "    ### create new \"region_final\" field for state and RESOLVE Zone compatibility (remove \"_%tech% from RESOLVE_zone region names\" and add hyphen to New Mexico for No_Cap/W2W rows)\n",
    "    selSite_merged_df[\"region_final\"] = np.where(selSite_merged_df.region.str.contains(\"_Wind\"), selSite_merged_df.region.str.replace(\"_Wind\", \"\"), \\\n",
    "                                                  np.where(selSite_merged_df.region.str.contains(\"_Solar\"), selSite_merged_df.region.str.replace(\"_Solar\", \"\"),\\\n",
    "                                                             np.where(selSite_merged_df.region.str.contains(\"_Geothermal\"), selSite_merged_df.region.str.replace(\"_Geothermal\", \"\"), selSite_merged_df.region)))\n",
    "    \n",
    "    ## Capped vs. No_Cap\n",
    "    selSite_merged_df['RESOLVE_cap'] = np.where(selSite_merged_df.RESOLVE_scenario.str.contains(\"Capped\"), \"Capped\",\n",
    "                                                np.where(selSite_merged_df.RESOLVE_scenario.str.contains(\"No_Cap\"), \"No_Cap\", selSite_merged_df.RESOLVE_scenario))\n",
    "    orig_len = len(selSite_merged_df)                                            \n",
    "   \n",
    "    ## SET new region columns\n",
    "    ### region_state: combine all of california, keep OR and WA separate for W2W analyses, rename Southern_Nevada as Nevada\n",
    "    selSite_merged_df['region_state'] = np.where(selSite_merged_df.selSites.str.contains(\"CA\"), \"California\",\n",
    "                                                 np.where(selSite_merged_df.region.str.contains(\"Southern_Nevada\"), \"Nevada\", \n",
    "                                                          np.where(selSite_merged_df.region.str.contains(\"New Mexico\"), \"New_Mexico\", selSite_merged_df.region_final)))\n",
    "    \n",
    "    ### region_state_PNW: like region_state, but names OR And WA as PNW\n",
    "    selSite_merged_df['region_state_PNW'] = np.where(selSite_merged_df.region.str.contains(\"Oregon\"), \"Pacific_Northwest\",\n",
    "                                          np.where(selSite_merged_df.region.str.contains(\"Washington\"), \"Pacific_Northwest\", selSite_merged_df.region_state))\n",
    "    \n",
    "    \n",
    "    print(\"Number of PNW rows added: \" + str(len(selSite_merged_df) - orig_len))\n",
    "\n",
    "    ### Calculate km2 of un-impacted land for stacked bar \n",
    "    selSite_merged_df[\"area_unimpactedSelSites_km2\"] = pd.to_numeric(selSite_merged_df[\"area_allSelSites_km2\"]) - pd.to_numeric(selSite_merged_df[\"area_envData_km2\"])\n",
    " \n",
    "    return selSite_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: pre-process housing density and gaplc csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCSV_hd_gaplc(csv, envDataType, valVars = [\"0\", \"553\",\"555\", \"556\", \"557\"]):\n",
    "    selSite_df = pd.read_csv(csv, keep_default_na=False)\n",
    "\n",
    "    ''' ### ADD INFRASTRUCTURE COLUMN ### '''\n",
    "    if \"selSite\" in csv:\n",
    "        selSite_df[\"infrastructure\"] = \"generation\"\n",
    "    if \"tx\" in csv:\n",
    "        selSite_df[\"infrastructure\"] = \"transmission\"\n",
    "\n",
    "    if envDataType == \"housingDen\":\n",
    "        ''' ### CONVERT \"mean\" TO \"NA\" FROM NaN OR BLANK ### '''\n",
    "        print(selSite_df[\"mean\"].dtype)\n",
    "        ## if a column value for \"area_envData_km2\" is NaN, assign 0 \n",
    "        selSite_df.loc[(selSite_df['region'].isna()) | (selSite_df['region'].astype(str) ==\"\") | (selSite_df['region'].astype(str) ==\"NA\"), ['mean', 'count']] = math.nan\n",
    "        ## if a column value for \"area_envData_km2\" is == \"NA\", assign 0 (these are runs with empty feature classes or no selected sites) \n",
    "        ## convert column datatype to float \n",
    "        selSite_df[\"mean\"] = pd.to_numeric(selSite_df[\"mean\"])\n",
    "        selSite_df[\"count\"] = pd.to_numeric(selSite_df[\"count\"])\n",
    "        print(selSite_df[\"mean\"].dtype)\n",
    "        \n",
    "    if (envDataType == \"gaplc\") or (envDataType == \"rangelands\"):\n",
    "        \n",
    "        ## Melt the dataframe\n",
    "        selSite_df = pd.melt(selSite_df, id_vars = [\"tech\", \"envCat\", \"scenario\", \"selSites\", \"region\", \"selSitesExist\", \"area_allSelSites_km2\"], \\\n",
    "                                           value_vars = valVars).rename(columns= {\"variable\" : \"landCoverType\", \"value\" : \"count\"})\n",
    "\n",
    "        ## change \"NA\" in count column to NaN if selSitesExist == 0\n",
    "        selSite_df.loc[(selSite_df[\"count\"].astype(str) == \"\") & (selSite_df.selSitesExist == 0), 'count'] = math.nan\n",
    "         ## change \"\" in count column to zeros if selSitesExist == 1\n",
    "        selSite_df.loc[(selSite_df[\"count\"].astype(str) == \"\") & (selSite_df.selSitesExist == 1), 'count'] = 0\n",
    "        selSite_df[\"count\"] = pd.to_numeric(selSite_df[\"count\"])\n",
    "\n",
    "        ## multiply counts by 30x30m = 0.0009 km2 \n",
    "        selSite_df[\"landCoverArea_km2\"] = selSite_df[\"count\"]*0.0009\n",
    "\n",
    "    '''### CREATE NEW envCat_scen TO PARSE OUT BaseUSeCat1 AS \"Base\" ###'''\n",
    "    selSite_df['envCat_scen'] = np.where(selSite_df.selSites.str.contains(\"BaseUseCat1\"), \"Base\", selSite_df.envCat) \n",
    "\n",
    "    ''' ### PARSE OUT CATEGORICAL COLUMNS FROM selSites COLUMN ### '''\n",
    "    #### geography: InState, Full_WECC, Part_WECc\n",
    "    selSite_df['geography'] = np.where(selSite_df.selSites.str.contains(\"InState\"), \"InState\", \\\n",
    "                                              np.where(selSite_df.selSites.str.contains(\"Full_WECC\"), \"Full_WECC\", \\\n",
    "                                                       np.where(selSite_df.selSites.str.contains(\"Part_WECC\"), \"Part_WECC\",\"NA\")))\n",
    "\n",
    "    ## RESOLVE scenario (Capped_Basecase, Capped_highDER, etc.)\n",
    "    selSite_df['RESOLVE_scenario'] = np.where(selSite_df.selSites.str.contains(\"Capped_Basecase\"), \"Capped_Basecase\",\n",
    "                                  np.where(selSite_df.selSites.str.contains(\"BaseUseCat1_Basecase\"), \"Capped_Basecase\",\n",
    "                                           np.where(selSite_df.selSites.str.contains(\"BaseUseCat1_highDER\"), \"Capped_highDER\",\n",
    "                                                    np.where(selSite_df.selSites.str.contains(\"BaseUseCat1_lowBatt\"), \"Capped_lowBatt\",\n",
    "                                                         np.where(selSite_df.selSites.str.contains(\"Capped_highDER\"), \"Capped_highDER\",\n",
    "                                                                 np.where(selSite_df.selSites.str.contains(\"Capped_lowBatt\"), \"Capped_lowBatt\",\n",
    "                                                                         np.where(selSite_df.selSites.str.contains(\"No_Cap_Basecase\"), \"No_Cap_Basecase\",\n",
    "                                                                                 np.where(selSite_df.selSites.str.contains(\"No_Cap_highDER\"), \"No_Cap_highDER\",\n",
    "                                                                                         np.where(selSite_df.selSites.str.contains(\"No_Cap_lowBatt\"), \"No_Cap_lowBatt\", \"NA\")))))))))\n",
    "\n",
    "    ### create new \"region_final\" field for state and RESOLVE Zone compatibility (remove \"_%tech% from RESOLVE_zone region names\" and add hyphen to New Mexico for No_Cap/W2W rows)\n",
    "    selSite_df[\"region_final\"] = np.where(selSite_df.region.str.contains(\"_Wind\"), selSite_df.region.str.replace(\"_Wind\", \"\"), \\\n",
    "                                                  np.where(selSite_df.region.str.contains(\"_Solar\"), selSite_df.region.str.replace(\"_Solar\", \"\"),\\\n",
    "                                                             np.where(selSite_df.region.str.contains(\"_Geothermal\"), selSite_df.region.str.replace(\"_Geothermal\", \"\"), selSite_df.region)))\n",
    "    \n",
    "    ## Capped vs. No_Cap\n",
    "    selSite_df['RESOLVE_cap'] = np.where(selSite_df.RESOLVE_scenario.str.contains(\"Capped\"), \"Capped\",\n",
    "                                                np.where(selSite_df.RESOLVE_scenario.str.contains(\"No_Cap\"), \"No_Cap\", selSite_df.RESOLVE_scenario))\n",
    "                                                \n",
    "    ''' ### COMBINE OR AND WA TO FORM PNW ROWS FOR W2W/STATE SCENARIOS ###''' \n",
    "    ## sum area_envData_km2 and area_allSelSites_km2\n",
    "    orig_len = len(selSite_df)\n",
    "    \n",
    "    if envDataType == \"housingDen\":\n",
    "        for scenario in selSite_df.selSites.unique():\n",
    "            subset = selSite_df[(selSite_df[\"selSites\"] == scenario) & ((selSite_df[\"region_final\"] == \"Oregon\") | (selSite_df[\"region_final\"] == \"Washington\"))]\n",
    "            if len(subset) >0:\n",
    "                ## create new row with updated calculations and new region_final name\n",
    "                if len(subset[subset[\"region_final\"] == \"Oregon\"]) >0:\n",
    "                    newRow = subset[(subset[\"region_final\"] == \"Oregon\")]\n",
    "                else:\n",
    "                    newRow = subset[(subset[\"region_final\"] == \"Washington\")]\n",
    "\n",
    "                ## Calculate count weighted averages\n",
    "                count_total = subset[\"count\"].sum()\n",
    "                subset[\"weightedMean\"] = (subset[\"mean\"]/count_total)*subset[\"count\"]\n",
    "                PNW_mean = subset[\"weightedMean\"].sum()\n",
    "\n",
    "                ## Assign calculated values to newRow\n",
    "                newRow[\"mean\"] = PNW_mean\n",
    "                newRow[\"count\"] = count_total\n",
    "                #newRow[\"percent_selSites\"] = area_envData_km2_tot/area_allSelSites_km2_tot\n",
    "                newRow[\"region_final\"] = \"Pacific_Northwest\"\n",
    "\n",
    "                ## add row to original df (selSite_df)\n",
    "                selSite_df = pd.concat([selSite_df,newRow], axis = 0, ignore_index = True)\n",
    "\n",
    "    ## SET new region columns\n",
    "    ### region_state: combine all of california, keep OR and WA separate for W2W analyses, rename Southern_Nevada as Nevada\n",
    "    selSite_df['region_state'] = np.where(selSite_df.selSites.str.contains(\"CA\"), \"California\",\n",
    "                                                 np.where(selSite_df.region.str.contains(\"Southern_Nevada\"), \"Nevada\", \n",
    "                                                          np.where(selSite_df.region.str.contains(\"New Mexico\"), \"New_Mexico\", selSite_df.region_final)))\n",
    "    \n",
    "    ### region_state_PNW: like region_state, but names OR And WA as PNW\n",
    "    selSite_df['region_state_PNW'] = np.where(selSite_df.region.str.contains(\"Oregon\"), \"Pacific_Northwest\",\n",
    "                                          np.where(selSite_df.region.str.contains(\"Washington\"), \"Pacific_Northwest\", selSite_df.region_state))\n",
    "                                          \n",
    "    if envDataType == \"housingDen\":\n",
    "    ## Recalculate the \"all\" region row for scenarios that have CA and OOS resources (need to take the weighted average of the two \"all\" regions)\n",
    "        for tech in selSite_df.tech.unique():\n",
    "            for cat in selSite_df.envCat_scen.unique():\n",
    "                for geo in selSite_df.geography.unique():\n",
    "                    for scen  in selSite_df.RESOLVE_scenario.unique():\n",
    "                        subset = selSite_df[(selSite_df[\"tech\"] == tech) & (selSite_df[\"envCat_scen\"] == cat) & (selSite_df[\"geography\"] == geo) & \\\n",
    "                                            (selSite_df[\"RESOLVE_scenario\"] == scen) & (selSite_df[\"region_final\"] == \"all\")]  \n",
    "                        if len(subset) == 2:\n",
    "                            ## Calculate count weighted averages\n",
    "                            count_total = subset[\"count\"].sum()\n",
    "                            subset[\"weightedMean\"] = (subset[\"mean\"]/count_total)*subset[\"count\"]\n",
    "                            all_mean = subset[\"weightedMean\"].sum()\n",
    "\n",
    "                            ## Assign calculated values\n",
    "                            ## take the region_state == \"all\" row and assign the \"mean\" column the new all_mean calculated value that includes CA\n",
    "                            selSite_df.loc[(selSite_df[\"tech\"] == tech) & (selSite_df[\"envCat_scen\"] == cat) & (selSite_df[\"geography\"] == geo) &\\\n",
    "                                           (selSite_df[\"RESOLVE_scenario\"] == scen) & (selSite_df[\"region_state\"] == \"all\"), 'mean']  = all_mean\n",
    "                            ## take the region_state == \"all\" row and assign the \"count\" column the new count_total calculated value that includes CA\n",
    "                            selSite_df.loc[(selSite_df[\"tech\"] == tech) & (selSite_df[\"envCat_scen\"] == cat) & (selSite_df[\"geography\"] == geo) & \\\n",
    "                                           (selSite_df[\"RESOLVE_scenario\"] == scen) & (selSite_df[\"region_state\"] == \"all\"), \"count\"] = count_total\n",
    "                            ## rename the region_state column for California's total, since all the supercrezs in California also have \"California\" in region_state (don't use the \"California\" value for making figures)\n",
    "                            selSite_df.loc[(selSite_df[\"tech\"] == tech) & (selSite_df[\"envCat_scen\"] == cat) & (selSite_df[\"geography\"] == geo) & \\\n",
    "                                           (selSite_df[\"RESOLVE_scenario\"] == scen) & (selSite_df[\"region_state\"] == \"California\") & \\\n",
    "                                           (selSite_df[\"region_final\"] == \"all\"), \"region_state\"] = \"California_all\"\n",
    "                        ## rename the region_state column for California's total in the inState scenarios (which don't have a len == 1)\n",
    "                        elif len(subset) == 1 and subset[\"region_state\"].where(subset.region_state == 'California', np.nan).max():\n",
    "                            selSite_df.loc[(selSite_df[\"tech\"] == tech) & (selSite_df[\"envCat_scen\"] == cat) & (selSite_df[\"geography\"] == geo) & \\\n",
    "                                           (selSite_df[\"RESOLVE_scenario\"] == scen) & (selSite_df[\"region_state\"] == \"California\") & \\\n",
    "                                           (selSite_df[\"region_final\"] == \"all\"), \"region_state\"] = \"California_all\"\n",
    "                            \n",
    "\n",
    "    print(\"Number of PNW rows added: \" + str(len(selSite_df) - orig_len))\n",
    "\n",
    "    ### Calculate km2 of un-impacted land for stacked bar \n",
    "    #selSite_df[\"area_unimpactedSelSites_km2\"] = pd.to_numeric(selSite_df[\"area_allSelSites_km2\"]) - pd.to_numeric(selSite_df[\"area_envData_km2\"])\n",
    "\n",
    "    return selSite_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply processCSV_hd_gaplc function to housing density and gaplc csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============> CHANGE INPUT <====================\n",
    "infrastructureType = \"tx_longHaul\" ## selSite or tx or tx_longHaul\n",
    "gaplc = 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_' + infrastructureType + '_SG13_gaplc_df.csv'\n",
    "hd = 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_' + infrastructureType + '_SG12_housingDensity_df.csv'\n",
    "rangelands = 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_' + infrastructureType + '_SG17_rangelands_df.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process housing density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "float64\n",
      "Number of PNW rows added: 2\n"
     ]
    }
   ],
   "source": [
    "hd_out = processCSV_hd_gaplc(hd, \"housingDen\")\n",
    "hd_out.to_csv(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_master_\" + infrastructureType +  \"_housingDensity_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process gaplc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PNW rows added: 0\n"
     ]
    }
   ],
   "source": [
    "gaplc_out = processCSV_hd_gaplc(gaplc, \"gaplc\", valVars = [\"0\", \"553\",\"555\", \"556\", \"557\"])\n",
    "gaplc_out.to_csv(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_master_\" + infrastructureType +  \"_gaplc_df_v2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process rangelands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PNW rows added: 0\n"
     ]
    }
   ],
   "source": [
    "rangelands_out = processCSV_hd_gaplc(rangelands, \"rangelands\", valVars = [\"0\", \"1\",\"2\",\"3\",\"4\",\"5\",\"11\",\"12\",\"21\",\"22\",\"23\",\"24\",\"31\",\"80\",\"81\",\"82\"])\n",
    "rangelands_out.to_csv(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_master_\" + infrastructureType +  \"_rangelands_df_v2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply processCSV function to other environmental metrics\n",
    "### Read list of csvs from envImpactAssessment directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG01_Cat1_Solar_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG01_Cat1_Wind_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG02_Cat2_Geothermal_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG02_Cat2_Solar_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG02_Cat2_Wind_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG03_Cat3_Geothermal_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG03_Cat3_Solar_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG03_Cat3_Wind_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG04_Cat4_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG05_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG06_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG07_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG08_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG09_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG10_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG11_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG12_housingDensity_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG13_gaplc_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG14_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG15_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG16_df.csv',\n",
       " 'C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_tx_longHaul_SG17_rangelands_df.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============> CHANGE INPUT <====================\n",
    "infrastructureType = \"tx_longHaul\" ## \"tx\" or \"selSite\" or \"tx_longHaul\"\n",
    "\n",
    "outputFolder = r\"C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\"\n",
    "## get selected sites csvs\n",
    "selSite_list = glob.glob(os.path.join(outputFolder, \"areaImpacted_\" + infrastructureType + \"_SG*\"))\n",
    "selSite_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read gaplc csv in order to merge area_allSelSites_km2 for all categories to each csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaplc = [x for x in selSite_list if \"gaplc\" in x]\n",
    "gaplc\n",
    "gaplc_df = pd.read_csv(gaplc[0], keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parsing function for each csv and concat into master_df, write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG01_Cat1_Solar_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG01_Cat1_Wind_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG02_Cat2_Geothermal_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG02_Cat2_Solar_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG02_Cat2_Wind_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG03_Cat3_Geothermal_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG03_Cat3_Solar_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG03_Cat3_Wind_df.csv\n",
      "object\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG04_Cat4_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG05_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG06_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG07_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG08_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG09_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG10_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG11_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG14_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG15_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "Working on C:\\Users\\Grace\\Documents\\TNC_beyond50\\PathTo100\\envImpactAssessment\\areaImpacted_tx_longHaul_SG16_df.csv\n",
      "float64\n",
      "float64\n",
      "Number of PNW rows added: 0\n",
      "266\n"
     ]
    }
   ],
   "source": [
    "area_list = []\n",
    "for csv in selSite_list:\n",
    "    if not(\"housingDensity\" in csv) and not(\"gaplc\" in csv) and not(\"rangelands\" in csv):\n",
    "        print(\"Working on \" + csv)\n",
    "        ## apply function to preprocess csvs \n",
    "        merged_df = processCSV(csv, gaplc_df)\n",
    "        \n",
    "        ## add merged df to list for concatenating at the end\n",
    "        area_list.append(merged_df)\n",
    "        \n",
    "master_df = pd.concat(area_list)\n",
    "\n",
    "print(len(master_df))\n",
    "## write to csv\n",
    "master_df.to_csv(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_master_\" + infrastructureType +  \"_df_v3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create legend and write to csv\n",
    "### Explanation of field/column flags for different \"zeros\"; writes to a master legend csv for interpreting the columns\n",
    "#### selSitesExist \n",
    "\n",
    "1: if the scenario was run and sites were chosen in that scenario and region and tech (these values were assigned BEFORE merging) <br/> \n",
    "0: if the scenario was run, but sites were NOT chosen for that scenario, env cat, region and tech\n",
    "\n",
    "#### impactEval\n",
    "1: if impact was calculated for this environmental category <br/>\n",
    "0: if impact WAS NOT calculated for this env cat because we expected ZERO impact (e.g., Cat 3 env datasets were not evaluated against Cat 3 selected sites because we would expect to see zero impact since Cat 3 env datasets were excluded in the Cat 3 suitable sites) <br/>\n",
    "0 flags are from rows added after merging with gaplc df\n",
    "\n",
    "#### scenRun\n",
    "1: if the scenario was run<br/>\n",
    "0: if the scenario was NOT run (e.g., W2W low-Batt for Cat 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tech_x', 'envCat_x', 'scenario', 'selSites', 'region', 'envData', 'area_envData_km2', 'area_allSelSites_km2_x', 'percent_selSites', 'impactEval', 'selSitesExist', 'area_allSelSites_km2_y', 'envCat_y', 'tech_y', 'infrastructure', 'area_allSelSites_km2', 'tech', 'envCat', 'envCat_scen', 'scenRun', 'geography', 'RESOLVE_scenario', 'region_final', 'region_state', 'RESOLVE_cap', 'area_unimpactedSelSites_km2'], dtype='object')"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = pd.DataFrame(data = {'tech_x': [\"IGNORE: technology for selected site or transmission. Where blank no area calculations were performed, refer to 'tech' column instead\"], \\\n",
    "                                 'envCat_x': [\"IGNORE: environmental category scenario for selectedsite or transmission. Where blank no area calculations were performed, refer to 'envCat' column instead\"],\\\n",
    "                                 'scenario': [\"Geography scenarios + RESOLVE scenario\"], \\\n",
    "                                 'selSites': [\"Name of selected sites or transmission polygon file\"], \\\n",
    "                                 'region' : [\"Name of region from selSites file\"], \\\n",
    "                                 'envData': [\"Name of enviromental metric dataset (e.g., Cat4_SG04 or CriticalHabitat_SG05)\"], \\\n",
    "                                 'area_envData_km2': [\"Area of environmental metric dataset that overlaps with the selected sites or transmission polygons. This is km2 of 'impact'\"],\\\n",
    "                                 'area_allSelSites_km2_x': [\"IGNORE: Area of just the selected sites or transmission polygons calculated during the area analyses. Where blank, refer to the 'area_allSelSites_km2' column\"],\\\n",
    "                                 'percent_selSites': [\"area_envData_km2/area_allSelSites_km2\"],\\\n",
    "                                 'impactEval': [\"Flag 1: if impact was calculated for this environmental category (pre-join/merge); Flag 0: if impact WAS NOT calculated for this env cat because we expected ZERO impact (post-join/merge). Rows ==0 could have needed impact evaluation (e.g., Cat 1 solar OOS), but were not actually evaluated because no sites existed.\"],\\\n",
    "                                 'selSitesExist': [\"Flag 1: if the scenario was run in RESOLVE and sites were chosen in that scenario, region, and tech; 0: if the RESOLVE scenario was run, but sites were NOT chosen for that scenario, env cat, region and tech (i.e., empty feature class); this field was joined from gaplc)\" ], \\\n",
    "                                 'area_allSelSites_km2_y': [\"IGNORE: Area of just the selected sites or transmission polygons calculated for the gaplc analyses. Where blank, refer to the 'area_allSelSites_km2' column\"], \\\n",
    "                                 'envCat_y': [\"IGNORE: environmental category scenario for selected site or transmission. Where blank no area calculations were performed, refer to 'envCat' column instead\"], \\\n",
    "                                 'tech_y': [\"IGNORE: technology for selected site or transmission. Where blank no area calculations were performed, refer to 'tech' column instead\"], \\\n",
    "                                 'infrastructure': [\"Generation or Transmission impacts\"], \\\n",
    "                                 'area_allSelSites_km2': [\"Area of just the selected sites or transmission polygons calculated during the area analyses. Used for calculating percentage or creating 'unimpacted area' stacked bar\"], \\\n",
    "                                 'tech': [\"technology for selected site or transmission\"], \\\n",
    "                                 'envCat' : [\"environmental category scenario used for for selected site (spatial disaggregation) or transmission.\"], \\\n",
    "                                 'envCat_scen' : [\"environmental category scenario used for for selected site or transmission--differs from envCat in that the RESOLVE Base scenario is referred to here as 'Base', not 'Cat1' (since Base required the use of Category 1 site suitability polygons for spatial disaggregation)\"], \\\n",
    "                                 'scenRun' : [\"Flag 1: if the scenario was run in RESOLVE; Flag 0: if the scenario was NOT run in RESOLVE (e.g., W2W low-Batt for Cat 1)\"], \\\n",
    "                                 'geography' : [\"InState, Full_WECC, or Part_WECC\"], \\\n",
    "                                 'RESOLVE_scenario': [\"Capped_Basecase, Capped_highDER, Capped_lowBatt, No_Cap_Basecase, No_Cap_highDER, No_Cap_lowBatt\"], \\\n",
    "                                 'region_final' : [\"Similar to 'region' field, but is not technology specific and contains Pacific_Northwest region for W2W assessment that sums Oregon and Washington's areas. \"], \\\n",
    "                                 'region_state': [\"Similar to 'region_final' field, but assigns all CA RESOLVE Zones as 'California' and assigns 'Southern_Nevada' to 'Nevada' (state), 'New Mexico' (state) is also renamed 'New_Mexico' \"],\\\n",
    "                                 'RESOLVE_cap' : [\"Either 'Capped' (RESOLVE Zone for OOS) or 'No_Cap' (states) \"],\\\n",
    "                                 'area_unimpactedSelSites_km2': [\"Area of selected sites or transmission that does not overlap with env metric dataset: 'area_allSelSites_km2' - 'area_envData_km2'\"]}).transpose()\n",
    "\n",
    "legend.to_csv(\"C:\\\\Users\\\\Grace\\\\Documents\\\\TNC_beyond50\\\\PathTo100\\\\envImpactAssessment\\\\areaImpacted_master_legend.csv\")                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check resulting processed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Capped_Basecase', 'Capped_highDER', 'Capped_lowBatt',\n",
       "       'No_Cap_Basecase', 'No_Cap_highDER', 'No_Cap_lowBatt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.RESOLVE_scenario.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[(master_df.impactEval == 0) & (master_df.selSitesExist == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tech_x', 'envCat_x', 'scenario', 'selSites', 'region', 'envData', 'area_envData_km2', 'area_allSelSites_km2_x', 'percent_selSites', 'impactEval', 'selSitesExist', 'area_allSelSites_km2_y', 'envCat_y', 'tech_y', 'infrastructure', 'area_allSelSites_km2', 'tech', 'envCat', 'envCat_scen', 'scenRun', 'geography', 'RESOLVE_scenario', 'region_final', 'area_unimpactedSelSites_km2'], dtype='object')"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
